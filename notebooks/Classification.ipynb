{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Base Image Classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import os\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import rasterio\n",
    "\n",
    "import os\n",
    "import numpy as np\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "import torchvision\n",
    "from torchvision import transforms\n",
    "from PIL import Image\n",
    "import rasterio\n",
    "\n",
    "from torch.utils.data import DataLoader, random_split\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torchvision import models\n",
    "from tqdm import tqdm \n",
    "\n",
    "sys.path.insert(0, os.path.abspath('../src'))\n",
    "from BigEarthNetclassification import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class_mapping, num_classes = getMappings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_path = r\"..\\data\\SampleDataset\\S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_26_57.png\"\n",
    "reference_map_path = r\"..\\data\\SampleDatasetReferenceMaps\\S2A_MSIL2A_20170613T101031_N9999_R022_T33UUP_26_57_reference_map.tif\"\n",
    "\n",
    "mapSample(image_path, reference_map_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "image_dir = r\"..\\data\\SampleDataset\"\n",
    "reference_map_base_path = r\"..\\data\\SamplesDatasetReferenceMaps\"\n",
    "dataset = SatelliteDataset(image_dir, reference_map_base_path, transform=transform)\n",
    "\n",
    "train_size = int(0.8 * len(dataset))\n",
    "val_size = int(0.1 * len(dataset))\n",
    "test_size = len(dataset) - train_size - val_size \n",
    "\n",
    "train_dataset, val_dataset, test_dataset = random_split(dataset, [train_size, val_size, test_size])\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)\n",
    "test_loader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
    "\n",
    "print(len(train_loader), len(val_loader), len(test_loader))\n",
    "\n",
    "#next(iter(train_loader))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.resnet50(pretrained=True)\n",
    "model.fc = nn.Linear(model.fc.in_features, num_classes)\n",
    "device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\n",
    "model = model.to(device)\n",
    "\n",
    "criterion = nn.BCEWithLogitsLoss()  # multi-label classification loss\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_epochs = 2\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "\n",
    "    for images, labels, id in tqdm(train_loader):\n",
    "        images, labels = images.to(device), labels.to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        outputs = model(images)\n",
    "\n",
    "        loss = criterion(outputs, labels)\n",
    "\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        running_loss += loss.item() * images.size(0)\n",
    "\n",
    "    epoch_loss = running_loss / len(train_loader.dataset)\n",
    "    print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {epoch_loss:.4f}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# save\n",
    "#torch.save(model.state_dict(), '..\\src\\checkpoints\\classifier.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Eval"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load\n",
    "model.load_state_dict(torch.load('..\\src\\checkpoints\\classifier.pth'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "preds, labels = evaluate_model(model, test_loader)\n",
    "calculate_metrics(preds, labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "sample_images, sample_labels, ids = next(iter(test_loader))\n",
    "print(sample_images.shape, sample_labels.shape)\n",
    "\n",
    "with torch.no_grad(): \n",
    "    sample_images, sample_labels = sample_images.to(device), sample_labels.to(device)\n",
    "    \n",
    "    sample_outputs = model(sample_images)\n",
    "    \n",
    "    sample_preds = (torch.sigmoid(sample_outputs) > 0.5).int()\n",
    "\n",
    "sample_images = sample_images.cpu()\n",
    "sample_preds = sample_preds.cpu()\n",
    "sample_labels = sample_labels.cpu()\n",
    "\n",
    "# Visualize the predictions\n",
    "visualize_predictions(sample_images, sample_preds, sample_labels)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import rasterio\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sample_images, sample_labels, ids = next(iter(test_loader))\n",
    "print(sample_images.shape, sample_labels.shape)\n",
    "\n",
    "with torch.no_grad():  # Disable gradient computation for inference\n",
    "    sample_images, sample_labels = sample_images.to(device), sample_labels.to(device)\n",
    "    sample_outputs = model(sample_images)\n",
    "    sample_preds = (torch.sigmoid(sample_outputs) > 0.5).int()\n",
    "\n",
    "sample_images = sample_images.cpu()\n",
    "sample_preds = sample_preds.cpu()\n",
    "sample_labels = sample_labels.cpu()\n",
    "\n",
    "reference_map_base_path = r\"C:\\Datasets\\BigEarthNet-S2\\Reference_Maps\\Reference_Maps\"\n",
    "visualize_predictions_with_map(sample_images, sample_preds, sample_labels, ids, reference_map_base_path, class_mapping)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
