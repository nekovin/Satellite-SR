{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Super-Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Prep"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "import rasterio\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from skimage.transform import resize\n",
    "import matplotlib.pyplot as plt\n",
    "from transformers import Swin2SRImageProcessor, Swin2SRForImageSuperResolution\n",
    "from torch.optim import Adam\n",
    "from tqdm import tqdm\n",
    "from PIL import Image\n",
    "import numpy as np\n",
    "\n",
    "hr_size = 128 \n",
    "\n",
    "class SRDataset(Dataset):\n",
    "    def __init__(self, data_paths, lr_size=(64, 64), hr_size=(128, 128)):\n",
    "        self.data_paths = data_paths\n",
    "        self.lr_size = lr_size\n",
    "        self.hr_size = hr_size\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        image_path = self.data_paths[idx]\n",
    "        \n",
    "        img = Image.open(image_path).convert('RGB')  # ensuring RGB format\n",
    "        \n",
    "        img = np.array(img) \n",
    "        \n",
    "        # Resize low-res and high-res images\n",
    "        lr_img = resize(img, self.lr_size, anti_aliasing=True, preserve_range=True)  # 64\n",
    "        hr_img = resize(img, self.hr_size, anti_aliasing=True, preserve_range=True)  # 128\n",
    "\n",
    "        lr_img = lr_img / 255.0 # normalisation\n",
    "        hr_img = hr_img / 255.0\n",
    "\n",
    "        # Convert to tensors and add RGB channels\n",
    "        lr_tensor = torch.tensor(lr_img, dtype=torch.float32).permute(2, 0, 1)  # [3, 64, 64] # this is to change the order of the dimensions\n",
    "        hr_tensor = torch.tensor(hr_img, dtype=torch.float32).permute(2, 0, 1)  # [3, 128, 128]\n",
    " \n",
    "\n",
    "        return lr_tensor, hr_tensor, image_path.split(\"\\\\\")[-1].split(\".\")[0]\n",
    "\n",
    "\n",
    "def filter_120x120_images(datasetPath):\n",
    "    imagePaths = []\n",
    "    for root, dirs, files in os.walk(datasetPath):\n",
    "        for file in files:\n",
    "            image_path = os.path.join(root, file)\n",
    "            with rasterio.open(image_path) as src:\n",
    "                # Check if the image is 120x120\n",
    "                if src.width == 120 and src.height == 120:\n",
    "                    imagePaths.append(image_path)\n",
    "                else:\n",
    "                    print(f\"Skipping image {file} with size {src.width}x{src.height}\")\n",
    "\n",
    "    return imagePaths\n",
    "\n",
    "datasetPath = r\"SampleDataset\"\n",
    "imagePaths = filter_120x120_images(datasetPath)\n",
    "\n",
    "dataset = SRDataset(imagePaths, lr_size=(64, 64), hr_size=(128, 128)) \n",
    "dataloader = DataLoader(dataset, batch_size=2, shuffle=True)\n",
    "\n",
    "print(len(dataset))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from skimage import filters\n",
    "from transformers import Swin2SRImageProcessor, Swin2SRForImageSuperResolution\n",
    "from tqdm import tqdm\n",
    "\n",
    "processor = Swin2SRImageProcessor.from_pretrained(\"caidas/swin2SR-classical-sr-x2-64\")\n",
    "model = Swin2SRForImageSuperResolution.from_pretrained(\"caidas/swin2SR-classical-sr-x2-64\")\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "model.to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define Gaussian blur with a kernel size\n",
    "blur = T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "\n",
    "# Function to detect keypoints and descriptors using SIFT\n",
    "def detect_edges(image_tensor):\n",
    "    image_np = image_tensor.cpu().permute(1, 2, 0).numpy()\n",
    "    gray_img = (image_np.mean(axis=2) * 255).astype('uint8')  # Convert to grayscale\n",
    "    \n",
    "    sift = cv2.SIFT_create()\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "    \n",
    "    # Create a blank image and draw keypoints for visualization\n",
    "    sift_image = cv2.drawKeypoints(gray_img, keypoints, None)\n",
    "    \n",
    "    # Convert back to tensor\n",
    "    sift_tensor = torch.tensor(sift_image, dtype=torch.float32).unsqueeze(0)\n",
    "    return sift_tensor\n",
    "\n",
    "\n",
    "from skimage.feature import corner_harris\n",
    "\n",
    "# Function to detect corners\n",
    "def detect_edges(image_tensor):\n",
    "    image_np = image_tensor.cpu().permute(1, 2, 0).numpy()\n",
    "    gray_img = image_np.mean(axis=2)  # Convert to grayscale\n",
    "    corners = corner_harris(gray_img)  # Harris corner detection\n",
    "    corner_tensor = torch.tensor(corners, dtype=torch.float32).unsqueeze(0)  # Shape [1, H, W]\n",
    "    return corner_tensor\n",
    "\n",
    "\n",
    "# Super-resolution guided by edge detection\n",
    "def feature_guided_super_resolution(lr_tensor):\n",
    "    edge_tensor = detect_edges(lr_tensor[0])  # Detect edges in the 64x64 image\n",
    "    edge_tensor = edge_tensor.to(device)\n",
    "    \n",
    "    # Combine the LR image (64x64) with edges for intermediate SR\n",
    "    combined_tensor = combine_image_with_features(lr_tensor[0], edge_tensor)\n",
    "\n",
    "    # Perform the first stage of super-resolution (64x64 -> 128x128)\n",
    "    with torch.no_grad():\n",
    "        inputs = {'pixel_values': combined_tensor.unsqueeze(0).to(device)}\n",
    "        outputs = model(**inputs)\n",
    "        sr_image = outputs.reconstruction  # Direct 128x128 super-resolved output\n",
    "\n",
    "    # Apply Gaussian blur to smooth the final image and reduce the edge highlights\n",
    "    sr_image = blur(sr_image)\n",
    "\n",
    "    return sr_image, edge_tensor\n",
    "\n",
    "# Visualization function\n",
    "def visualize_images_with_features(lr_image, final_sr_image, edge_tensor):\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    plt.subplot(1, 3, 1)\n",
    "    lr_img = lr_image.permute(1, 2, 0).cpu().numpy()\n",
    "    plt.imshow(lr_img)\n",
    "    plt.title(\"Low-Resolution Input (64x64)\")\n",
    "    \n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(edge_tensor.cpu().squeeze(), cmap='gray')\n",
    "    plt.title(\"Detected Edges\")\n",
    "\n",
    "    plt.subplot(1, 3, 3)\n",
    "    final_sr_img = final_sr_image[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    plt.imshow(final_sr_img)\n",
    "    plt.title(\"Super-Resolved Output (128x128) [Original]\")\n",
    "\n",
    "    plt.show()\n",
    "\n",
    "# Apply 2x SR with edge detection\n",
    "for batch_idx, (lr_tensor, hr_tensor, img_path) in enumerate(dataloader):\n",
    "    lr_tensor = lr_tensor.to(device)\n",
    "    \n",
    "    # 64x64 to 128x128 super-resolution\n",
    "    final_sr_image, edge_tensor = feature_guided_super_resolution(lr_tensor)\n",
    "\n",
    "    # Visualize the 64x64 input and 128x128 output with edges\n",
    "    visualize_images_with_features(lr_tensor[0], final_sr_image, edge_tensor)\n",
    "\n",
    "    break  # Stop after one batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define Gaussian blur with a kernel size\n",
    "blur = T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "\n",
    "def extract_sift_features(image_tensor):\n",
    "    # Convert tensor to numpy array and prepare for SIFT\n",
    "    image_np = image_tensor.cpu().permute(1, 2, 0).numpy()\n",
    "    gray_img = cv2.cvtColor(np.uint8(image_np * 255), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Initialize SIFT detector\n",
    "    sift = cv2.SIFT_create()\n",
    "    \n",
    "    # Detect keypoints and compute descriptors\n",
    "    keypoints, descriptors = sift.detectAndCompute(gray_img, None)\n",
    "    \n",
    "    # Create a feature map highlighting SIFT keypoints\n",
    "    feature_map = np.zeros_like(gray_img, dtype=np.float32)\n",
    "    \n",
    "    # Draw keypoints with their scales\n",
    "    for kp in keypoints:\n",
    "        x, y = int(kp.pt[0]), int(kp.pt[1])\n",
    "        size = int(kp.size)\n",
    "        cv2.circle(feature_map, (x, y), size, 1.0, -1)\n",
    "    \n",
    "    # Normalize and convert to tensor\n",
    "    feature_map = feature_map / (feature_map.max() + 1e-8)\n",
    "    feature_tensor = torch.tensor(feature_map, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    return feature_tensor, keypoints, descriptors\n",
    "\n",
    "def combine_image_with_features(image_tensor, feature_tensor, weight=0.3):\n",
    "    # Normalize image and feature tensors\n",
    "    image_tensor = (image_tensor - image_tensor.min()) / (image_tensor.max() - image_tensor.min())\n",
    "    feature_tensor = (feature_tensor - feature_tensor.min()) / (feature_tensor.max() - feature_tensor.min())\n",
    "    \n",
    "    # Add SIFT features to the image with specified weight\n",
    "    combined_tensor = image_tensor + (weight * feature_tensor)\n",
    "    combined_tensor = combined_tensor / (combined_tensor.max() + 1e-8)\n",
    "    \n",
    "    return combined_tensor\n",
    "\n",
    "def sift_guided_super_resolution(lr_tensor):\n",
    "    # Extract SIFT features from the LR image\n",
    "    sift_tensor, keypoints, descriptors = extract_sift_features(lr_tensor[0])\n",
    "    sift_tensor = sift_tensor.to(device)\n",
    "    \n",
    "    # Combine the LR image with SIFT features\n",
    "    combined_tensor = combine_image_with_features(lr_tensor[0], sift_tensor)\n",
    "\n",
    "    # Perform super-resolution\n",
    "    with torch.no_grad():\n",
    "        inputs = {'pixel_values': combined_tensor.unsqueeze(0).to(device)}\n",
    "        outputs = model(**inputs)\n",
    "        sr_image = outputs.reconstruction\n",
    "    \n",
    "    # Apply Gaussian blur to smooth the final image\n",
    "    sr_image = blur(sr_image)\n",
    "\n",
    "    return sr_image, sift_tensor, keypoints\n",
    "\n",
    "def visualize_images_with_sift(lr_image, final_sr_image, sift_tensor, keypoints):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Display LR input\n",
    "    plt.subplot(1, 3, 1)\n",
    "    lr_img = lr_image.permute(1, 2, 0).cpu().numpy()\n",
    "    plt.imshow(lr_img)\n",
    "    plt.title(\"Low-Resolution Input (64x64)\")\n",
    "    \n",
    "    # Display SIFT features\n",
    "    plt.subplot(1, 3, 2)\n",
    "    lr_img_with_kp = lr_img.copy()\n",
    "    plt.imshow(sift_tensor.cpu().squeeze(), cmap='hot')\n",
    "    plt.title(\"SIFT Feature Map\")\n",
    "    \n",
    "    # Display SR output\n",
    "    plt.subplot(1, 3, 3)\n",
    "    final_sr_img = final_sr_image[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    plt.imshow(final_sr_img)\n",
    "    plt.title(\"Super-Resolved Output (128x128)\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply 2x SR with SIFT features\n",
    "for batch_idx, (lr_tensor, hr_tensor, img_path) in enumerate(dataloader):\n",
    "    lr_tensor = lr_tensor.to(device)\n",
    "    \n",
    "    # 64x64 to 128x128 super-resolution with SIFT guidance\n",
    "    final_sr_image, sift_tensor, keypoints = sift_guided_super_resolution(lr_tensor)\n",
    "\n",
    "    # Visualize results\n",
    "    visualize_images_with_sift(lr_tensor[0], final_sr_image, sift_tensor, keypoints)\n",
    "    \n",
    "    break  # Stop after one batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "# Define Gaussian blur with a kernel size\n",
    "blur = T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "\n",
    "def detect_satellite_edges(image_tensor):\n",
    "    # Convert tensor to numpy array\n",
    "    image_np = image_tensor.cpu().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Convert to grayscale\n",
    "    gray_img = cv2.cvtColor(np.uint8(image_np * 255), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Gaussian blur to reduce noise\n",
    "    blurred = cv2.GaussianBlur(gray_img, (3, 3), 0)\n",
    "    \n",
    "    # Apply Canny edge detection with automatic threshold detection\n",
    "    median = np.median(blurred)\n",
    "    lower = int(max(0, (1.0 - 0.33) * median))\n",
    "    upper = int(min(255, (1.0 + 0.33) * median))\n",
    "    edges = cv2.Canny(blurred, lower, upper)\n",
    "    \n",
    "    # Dilate edges slightly to make them more prominent\n",
    "    kernel = np.ones((2,2), np.uint8)\n",
    "    edges = cv2.dilate(edges, kernel, iterations=1)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    edge_tensor = torch.tensor(edges, dtype=torch.float32).unsqueeze(0)\n",
    "    edge_tensor = edge_tensor / 255.0  # Normalize to [0,1]\n",
    "    \n",
    "    return edge_tensor\n",
    "\n",
    "def enhance_edges(edge_tensor):\n",
    "    \"\"\"Additional processing to enhance edges for satellite imagery\"\"\"\n",
    "    # Apply morphological operations to strengthen significant edges\n",
    "\n",
    "    edge_tensor = edge_tensor.to('cpu')\n",
    "    \n",
    "    edge_np = edge_tensor.squeeze().numpy()\n",
    "    \n",
    "    # Close small gaps\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    edge_np = cv2.morphologyEx(edge_np, cv2.MORPH_CLOSE, kernel)\n",
    "    \n",
    "    # Remove small noise\n",
    "    edge_np = cv2.morphologyEx(edge_np, cv2.MORPH_OPEN, kernel)\n",
    "    \n",
    "    return torch.tensor(edge_np, dtype=torch.float32).unsqueeze(0)\n",
    "\n",
    "def combine_image_with_features(image_tensor, feature_tensor):\n",
    "    # Normalize image and feature tensors\n",
    "    image_tensor = (image_tensor - image_tensor.min()) / (image_tensor.max() - image_tensor.min())\n",
    "    feature_tensor = (feature_tensor - feature_tensor.min()) / (feature_tensor.max() - feature_tensor.min())\n",
    "    \n",
    "    # Add edges to the image with an appropriate weight for satellite imagery\n",
    "    weight = 0.4  # Increased weight for satellite imagery edges\n",
    "    image_tensor = image_tensor.to(device)\n",
    "    feature_tensor = feature_tensor.to(device)\n",
    "    combined_tensor = image_tensor + (weight * feature_tensor)\n",
    "    combined_tensor = combined_tensor / (combined_tensor.max() + 1e-8)\n",
    "    \n",
    "    return combined_tensor\n",
    "\n",
    "def edge_guided_super_resolution(lr_tensor):\n",
    "    # Detect edges in the LR image\n",
    "    edge_tensor = detect_satellite_edges(lr_tensor[0])\n",
    "    edge_tensor = edge_tensor.to(device)\n",
    "    \n",
    "    # Enhance edges\n",
    "    edge_tensor = enhance_edges(edge_tensor)\n",
    "    \n",
    "    # Combine the LR image with edges\n",
    "    combined_tensor = combine_image_with_features(lr_tensor[0], edge_tensor)\n",
    "\n",
    "    # Perform super-resolution\n",
    "    with torch.no_grad():\n",
    "        inputs = {'pixel_values': combined_tensor.unsqueeze(0).to(device)}\n",
    "        outputs = model(**inputs)\n",
    "        sr_image = outputs.reconstruction\n",
    "    \n",
    "    # Apply subtle Gaussian blur to smooth any edge artifacts\n",
    "    sr_image = blur(sr_image)\n",
    "\n",
    "    return sr_image, edge_tensor\n",
    "\n",
    "def visualize_satellite_images(lr_image, final_sr_image, edge_tensor):\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Display LR input\n",
    "    plt.subplot(1, 3, 1)\n",
    "    lr_img = lr_image.permute(1, 2, 0).cpu().numpy()\n",
    "    plt.imshow(lr_img)\n",
    "    plt.title(\"Low-Resolution Satellite Image\")\n",
    "    \n",
    "    # Display detected edges\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(edge_tensor.cpu().squeeze(), cmap='gray')\n",
    "    plt.title(\"Detected Edges\")\n",
    "    \n",
    "    # Display SR output\n",
    "    plt.subplot(1, 3, 3)\n",
    "    final_sr_img = final_sr_image[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    plt.imshow(final_sr_img)\n",
    "    plt.title(\"Super-Resolved Output\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Apply SR with edge detection\n",
    "for batch_idx, (lr_tensor, hr_tensor, img_path) in enumerate(dataloader):\n",
    "    lr_tensor = lr_tensor.to(device)\n",
    "    \n",
    "    # Perform edge-guided super-resolution\n",
    "    final_sr_image, edge_tensor = edge_guided_super_resolution(lr_tensor)\n",
    "\n",
    "    # Visualize results\n",
    "    visualize_satellite_images(lr_tensor[0], final_sr_image, edge_tensor)\n",
    "    \n",
    "    break  # Stop after one batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "import torchvision.transforms as T\n",
    "import cv2\n",
    "import numpy as np\n",
    "\n",
    "# Define Gaussian blur with a kernel size\n",
    "blur = T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "\n",
    "def detect_harris_corners(image_tensor):\n",
    "    \"\"\"\n",
    "    Apply Harris corner detection and convert corners to edge-like features\n",
    "    \"\"\"\n",
    "    # Convert tensor to numpy array\n",
    "    image_np = image_tensor.cpu().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Convert to grayscale and normalize\n",
    "    gray_img = cv2.cvtColor(np.uint8(image_np * 255), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Harris corner detection\n",
    "    harris_response = cv2.cornerHarris(gray_img, blockSize=2, ksize=3, k=0.04)\n",
    "    \n",
    "    # Normalize the response\n",
    "    harris_response = cv2.normalize(harris_response, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Dilate to connect nearby corners and create edge-like features\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    harris_dilated = cv2.dilate(harris_response, kernel)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    feature_tensor = torch.tensor(harris_dilated, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    return feature_tensor\n",
    "\n",
    "def combine_image_with_features(image_tensor, feature_tensor):\n",
    "    \"\"\"\n",
    "    Combine the original image with Harris corner features\n",
    "    \"\"\"\n",
    "    # Normalize tensors\n",
    "    image_tensor = (image_tensor - image_tensor.min()) / (image_tensor.max() - image_tensor.min())\n",
    "    feature_tensor = (feature_tensor - feature_tensor.min()) / (feature_tensor.max() - feature_tensor.min())\n",
    "    \n",
    "    # Combine with appropriate weight for satellite imagery\n",
    "    weight = 0.3\n",
    "    combined = image_tensor + (weight * feature_tensor)\n",
    "    combined = combined / (combined.max() + 1e-8)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def harris_guided_super_resolution(lr_tensor):\n",
    "    \"\"\"\n",
    "    Perform super-resolution guided by Harris corner features\n",
    "    \"\"\"\n",
    "    # Detect Harris corners and convert to edge-like features\n",
    "    feature_tensor = detect_harris_corners(lr_tensor[0])\n",
    "    feature_tensor = feature_tensor.to(device)\n",
    "    \n",
    "    # Combine image with corner features\n",
    "    combined_tensor = combine_image_with_features(lr_tensor[0], feature_tensor)\n",
    "\n",
    "    # Perform super-resolution\n",
    "    with torch.no_grad():\n",
    "        inputs = {'pixel_values': combined_tensor.unsqueeze(0).to(device)}\n",
    "        outputs = model(**inputs)\n",
    "        sr_image = outputs.reconstruction\n",
    "    \n",
    "    # Apply subtle blur to reduce any artifacts\n",
    "    sr_image = blur(sr_image)\n",
    "\n",
    "    return sr_image, feature_tensor\n",
    "\n",
    "def visualize_results(lr_image, sr_image, feature_tensor):\n",
    "    \"\"\"\n",
    "    Visualize the original, Harris features, and super-resolved images\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(15, 5))\n",
    "    \n",
    "    # Original image\n",
    "    plt.subplot(1, 3, 1)\n",
    "    lr_img = lr_image.permute(1, 2, 0).cpu().numpy()\n",
    "    plt.imshow(lr_img)\n",
    "    plt.title(\"Original Satellite Image\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Harris corner features\n",
    "    plt.subplot(1, 3, 2)\n",
    "    plt.imshow(feature_tensor.cpu().squeeze(), cmap='hot')\n",
    "    plt.title(\"Harris Corner Features\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    # Super-resolved image\n",
    "    plt.subplot(1, 3, 3)\n",
    "    sr_img = sr_image[0].permute(1, 2, 0).cpu().detach().numpy()\n",
    "    plt.imshow(sr_img)\n",
    "    plt.title(\"Super-Resolved Result\")\n",
    "    plt.axis('off')\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "\n",
    "# Process images\n",
    "for batch_idx, (lr_tensor, hr_tensor, img_path) in enumerate(dataloader):\n",
    "    lr_tensor = lr_tensor.to(device)\n",
    "    \n",
    "    # Apply Harris-guided super-resolution\n",
    "    sr_image, feature_tensor = harris_guided_super_resolution(lr_tensor)\n",
    "    \n",
    "    # Visualize results\n",
    "    visualize_results(lr_tensor[0], sr_image, feature_tensor)\n",
    "    \n",
    "    break  # Process one batch for demonstration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn.functional as F\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "import cv2\n",
    "from skimage.metrics import peak_signal_noise_ratio, structural_similarity, mean_squared_error\n",
    "import torchvision.transforms as T\n",
    "\n",
    "# Define Gaussian blur with a kernel size\n",
    "blur = T.GaussianBlur(kernel_size=(3, 3), sigma=(0.1, 2.0))\n",
    "\n",
    "def detect_harris_corners(image_tensor):\n",
    "    \"\"\"\n",
    "    Apply Harris corner detection and convert corners to edge-like features\n",
    "    \"\"\"\n",
    "    # Convert tensor to numpy array\n",
    "    image_np = image_tensor.cpu().permute(1, 2, 0).numpy()\n",
    "    \n",
    "    # Convert to grayscale and normalize\n",
    "    gray_img = cv2.cvtColor(np.uint8(image_np * 255), cv2.COLOR_RGB2GRAY)\n",
    "    \n",
    "    # Apply Harris corner detection\n",
    "    harris_response = cv2.cornerHarris(gray_img, blockSize=2, ksize=3, k=0.04)\n",
    "    \n",
    "    # Normalize the response\n",
    "    harris_response = cv2.normalize(harris_response, None, 0, 1, cv2.NORM_MINMAX)\n",
    "    \n",
    "    # Dilate to connect nearby corners and create edge-like features\n",
    "    kernel = np.ones((3,3), np.uint8)\n",
    "    harris_dilated = cv2.dilate(harris_response, kernel)\n",
    "    \n",
    "    # Convert to tensor\n",
    "    feature_tensor = torch.tensor(harris_dilated, dtype=torch.float32).unsqueeze(0)\n",
    "    \n",
    "    return feature_tensor\n",
    "\n",
    "def combine_image_with_features(image_tensor, feature_tensor):\n",
    "    \"\"\"\n",
    "    Combine the original image with Harris corner features\n",
    "    \"\"\"\n",
    "    # Normalize tensors\n",
    "    image_tensor = (image_tensor - image_tensor.min()) / (image_tensor.max() - image_tensor.min())\n",
    "    feature_tensor = (feature_tensor - feature_tensor.min()) / (feature_tensor.max() - feature_tensor.min())\n",
    "    \n",
    "    # Combine with appropriate weight for satellite imagery\n",
    "    weight = 0.3\n",
    "    combined = image_tensor + (weight * feature_tensor)\n",
    "    combined = combined / (combined.max() + 1e-8)\n",
    "    \n",
    "    return combined\n",
    "\n",
    "def super_resolve_images(dataloader, model, device):\n",
    "    model.eval()\n",
    "    psnr_scores = []\n",
    "    ssim_scores = []\n",
    "    mse_scores = []\n",
    "    \n",
    "    for batch_idx, (lr_tensor, hr_tensor, img_path) in enumerate(tqdm(dataloader)):\n",
    "        lr_tensor = lr_tensor.to(device)\n",
    "        hr_tensor = hr_tensor.to(device)\n",
    "\n",
    "        for i in range(hr_tensor.shape[0]):\n",
    "            # Get current image\n",
    "            lr_image = lr_tensor[i]\n",
    "            hr_image = hr_tensor[i]\n",
    "\n",
    "            # Detect Harris corners and combine with image\n",
    "            feature_tensor = detect_harris_corners(lr_image)\n",
    "            feature_tensor = feature_tensor.to(device)\n",
    "            combined_tensor = combine_image_with_features(lr_image, feature_tensor)\n",
    "\n",
    "            # Super-resolution pass\n",
    "            with torch.no_grad():\n",
    "                inputs = {'pixel_values': combined_tensor.unsqueeze(0)}\n",
    "                outputs = model(**inputs)\n",
    "                sr_image = outputs.reconstruction\n",
    "\n",
    "            # Apply subtle blur to reduce artifacts\n",
    "            sr_image = blur(sr_image)\n",
    "\n",
    "            # Resize original HR image to match SR output size\n",
    "            resized_hr_image = F.interpolate(hr_image.unsqueeze(0), \n",
    "                                           size=(sr_image.shape[2], sr_image.shape[3]), \n",
    "                                           mode='bilinear', \n",
    "                                           align_corners=False).squeeze(0)\n",
    "\n",
    "            # Move images to CPU and convert to numpy arrays\n",
    "            hr_img_np = resized_hr_image.cpu().permute(1, 2, 0).numpy()\n",
    "            sr_img_np = sr_image[0].cpu().permute(1, 2, 0).detach().numpy()\n",
    "\n",
    "            # Ensure images are in range [0, 1]\n",
    "            hr_img_np = np.clip(hr_img_np, 0, 1)\n",
    "            sr_img_np = np.clip(sr_img_np, 0, 1)\n",
    "\n",
    "            # Calculate metrics\n",
    "            psnr_value = peak_signal_noise_ratio(hr_img_np, sr_img_np, data_range=1.0)\n",
    "            ssim_value = structural_similarity(hr_img_np, sr_img_np, channel_axis=2, data_range=1.0, win_size=7)\n",
    "            mse_value = mean_squared_error(hr_img_np, sr_img_np)\n",
    "\n",
    "            # Store metrics\n",
    "            psnr_scores.append(psnr_value)\n",
    "            ssim_scores.append(ssim_value)\n",
    "            mse_scores.append(mse_value)\n",
    "\n",
    "            # Visualize results\n",
    "            plt.figure(figsize=(15, 5))\n",
    "            \n",
    "            # Original HR image\n",
    "            plt.subplot(1, 3, 1)\n",
    "            plt.imshow(hr_img_np)\n",
    "            plt.title(f\"Original HR Image\\nSize: {hr_img_np.shape[:2]}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Harris corner features\n",
    "            plt.subplot(1, 3, 2)\n",
    "            plt.imshow(feature_tensor.cpu().squeeze(), cmap='hot')\n",
    "            plt.title(\"Harris Corner Features\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            # Super-resolved image\n",
    "            plt.subplot(1, 3, 3)\n",
    "            plt.imshow(sr_img_np)\n",
    "            plt.title(f\"Super-Resolved Image\\nSize: {sr_img_np.shape[:2]}\\nPSNR: {psnr_value:.2f}\")\n",
    "            plt.axis('off')\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.show()\n",
    "\n",
    "    # Calculate average metrics\n",
    "    avg_psnr = np.mean(psnr_scores)\n",
    "    avg_ssim = np.mean(ssim_scores)\n",
    "    avg_mse = np.mean(mse_scores)\n",
    "\n",
    "    print(f\"Average PSNR: {avg_psnr:.4f}\")\n",
    "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
    "    print(f\"Average MSE: {avg_mse:.8f}\")\n",
    "\n",
    "    return hr_img_np, sr_img_np, avg_psnr, avg_ssim, avg_mse\n",
    "\n",
    "# Run the super-resolution process\n",
    "hr_img, sr_img, avg_psnr, avg_ssim, avg_mse = super_resolve_images(dataloader, model, device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_psnr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_ssim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "avg_mse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
